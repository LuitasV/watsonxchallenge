Supports any cloud or on-premises.The watsonx platform is priced competitively and with transparency. Utilization information is proactively provided to customers with usage details per mutually agreed upon frequency or on an ad-hoc basis. .The watsonx offering is a modern cloud native platform designed as an open framework to easily facilitate our Customer's cloud journeys. .watsonx.governance offers risk management, regulatory compliance and life cycle management for the models. Targeted Policy packs for specific regulations are in the roadmap for release in Q4. Users can be on-boarded via an easy to use GUI. Users can see performance metrics. The platform provides an SDK and API's for prompt engineering and for text generation.  The API and SDK can be used to integrate with applications such as conversational AI and RAG sources. The watsonx platform is able to integrate with other cloud environments.  Models can be trained with data in other cloud environments.  Models can be monitored with watsonx.governance even if deployed on other cloud environments.Costs can be calculated down to the services and group/user level. Resource usage is readily visible to users.IBM works hard to ensure that the watsonx platform cost is efficient and market competitive.Costs can be calculated down to the services and group/user level.We do not anticipate any problems as IBM currently has practices proven in both SaaS and On Prem products in use across a large customer base. .The watsonx platform is an open SaaS solution designed to work with multiple cloud control frameworks. . watsonx.governance will support compliance and auditing requirements.IBM has a dedicated research center called the IBM Research AI Hardware Center, which is focused on enabling the next generation of chips and systems that support the massive computing power and unprecedented speed that artificial intelligence needs to reach its full potential. See also point 1.5: IBM Research continues to use the AI-optimized, cloud-native supercomputer IBM Vela, which is continuously used for the development of new large language models and the advancement of current models. IBM Research has also developed IBM NorthPole, an innovative AI chip architecture that represents a breakthrough in chip design and is specifically optimized for AI workloads. Compared to traditional GPUs and CPUs, NorthPole has outperformed when using ResNet-50 as a benchmark in terms of power efficiency, latency, and required storage space (see https://doi.org/10.1126/science.adh1174).watsonx offers a variety of customization and integration options, including an easy-to-use graphical user interface and APIs, Jupyter Notebooks, the Prompt Lab with Prompt Templates, and the Tuning Studio. In addition, you can choose from a wide range of IBM's own, open source and third-party models, with watsonx allowing you to set all the model parameters that the models support. In addition, your own model can be integrated into our solution (bring your own model, planned for Q1 2024). The watsonx SaaS solution, which is based on the IBM Cloud, does not require any further dependencies. When installing watsonx as software on-premises, an airgapped environment is also possible. Information on the architecture and hardware can be found in points 4.  Information on the architecture and hardware can be found in points 4.12, 5.2, 5.3 and 5.4. Furthermore, deployment on AWS is possible (watsonx.data) or planned in the future (watsonx.ai & watsonx.governance in 2024). many of IBM's in-house developed products also integrate open-source components to serve a broad and open ecosystem or widely used standards. The open-source components included in each product are documented in the respective license information. Subject to the IBM Passport Advantage Terms, IBM's obligation to defend against claims of infringement of an intellectual property right or copyright includes claims relating to open source code that IBM selects and embeds in an IBM program. Note, there are restrictions to Watsonx.ai indemnity - for 3rd party provided models. The integrated open-source components are documented via the respective license information for each product. E.g. watsonx.ai: https://www.ibm.com/support/customer/csol/terms/?id=L-GWKC-WRKNKA&lc=en-non-ibm-licence or watsonx.data: https://www.ibm.com/support/customer/csol/terms/?id=L-SPHR-M252JU&lc=en-non-ibm-licence.IBM provides extensive information and documentation for its products. Below is a selection of relevant sources: - Developer Portal: Extensive compilation of articles and blog posts, use cases, demo videos, course offerings, and tutorials. -> https://developer.ibm.com/components/watsonx/ - Technical Documentation: Extensive compilation of technical documentation, support technotes, announcement letters, etc. -> https://www.ibm.com/docs/en/search/watsonx https://www.ibm.com/docs/en/search/watsonx - Support Library and Knowledgebase: Access to extensive documentation of support cases, fixes, known errors and other documentation -> https://www.ibm.com/mysupport/s/ibm-community-support-search-results.To use watsonx as a SaaS, all you need is an internet connection and a web browser. Supported browsers include Google Chrome, Mozilla Firefox, and Microsoft Edge. The hardware requirements to use watsonx as software on-premises depend on the planned use cases. An example configuration is shown in point 5.2.SaaS deployment: Despite data distribution across multiple locations, access to the model is possible. Local OnPremise SW Deployment: Yes, either duplicate installation per data environment, or network access, no stretched clusters possible in Redhat Openshift. Watsonx offers extensive role-based access control (RBAC) options. A role is a set of privileges that are assigned to a user so that they can perform and manage certain tasks in Watsonx. Identity and Access Management (IAM) enables secure authentication of users for platform services and unified control of access to resources. Users can be grouped into an access group to easily assign access to all members of the group at the same level. Roles can also be assigned to a group. In a SaaS deployment, the IAM access policies can be used to assign access permissions to users and service IDs for resources within the account. Trusted profiles can also be used to group and grant access permissions to users, as well as service and app identities. By specifying conditions based on SAML attributes for users whose identity is federated from an external identity provider, users can be granted access to resources without having to invite users to the account (provided the users meet the defined conditions). For service and app identities, fine-grained authorization can be defined for all applications running in a compute resource without the need to create service IDs or manage the lifecycle of API keys for applications. Roles and permissions: https://dataplatform.cloud.ibm.com/docs/content/wsj/admin/your-roles.html?context=cpdaas&audience=wdp In a local SW deployment, group assignments can be dynamically defined by rules via attributes and LDAP characteristics. API keys at platform or instance level allow differentiated authorization for a wide variety of applications. Roles and permissions: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=users-predefined-roles-permissions-in-cloud-pak-data#roles-permissions__permssion Further descriptions: SaaS: https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/security-account.html?context=cpdaas Software: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=a-managing-users-1. with watsonx as a local on-premise software deployment, one key can be used per tenant if the tenants are separated at the namespace level. In SaaS deployments, this can be implemented by designing the environment(s) accordingly. In this way, different projects, deployments or storage pools can be defined for each client, each with its own encryption.see answer x.x It is also possible to integrate 2-factor authentication (2FA) or multi-factor authentication (MFA) for users and administrators for SaaS use in the IBM Cloud. This adds an extra layer of security to your account by requiring an additional authentication factor for all users in addition to the ID and password.SaaS see: https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/security-data.html?context=cpdaas&audience=wdp Software OnPremise: KMS from open shift possible: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=planning-storage-considerations https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=considerations-kerberos-authentication. security and encryption concepts can be implemented at different levels. Security for the IBM Watsonx platform is configurable in multiple layers to ensure that your data, applications, and user identity are protected on-premise and in any cloud. The security levels are: - Network security – Network security protects the network infrastructure and the points where your database or applications interact with the cloud. - Account security – Account security includes IAM and access groups/roles that can be configured both on-premise and in the IBM Cloud. Data security – Data security with encryption methods, e.g. on-premise by IBM Storage SW, which is also used as UEL at BWI, provides data encryption for data at rest and in transit, as well as other security mechanisms related to data. In SaaS deployments, cloud object storage encryption can be used.Data security – Data security with encryption methods, e.g. on-premise by IBM Storage SW, provides data encryption for data at rest and in transit, as well as other security mechanisms related to data. In SaaS deployments, cloud object storage encryption can be used. There are no functional dependencies. Outside the defined network, no call-in or call-out is necessary, air-gapped installation and operation are possible.watsonx.ai offers various REST APIs (e.g. to use a deployed prompt for LLMs or to use an LLM directly), Python libraries (e.g. https://github.com/IBM/watsonx-prompt-lab ) and SDKs (e.g. Jupyter Notebook environments). watsonx.ai than OnPremise software can use SAML (Security Assertion Markup Language), SSO (single-sign-on) and LDAP (Lightweight Directory Access Protocol) together or individually. An enterprise-grade LDAP password management provider can be used. Users can be added manually, individual LDAP users can be included by adding them to a user group, or access can be granted to all members of an LDAP group by adding an LDAP group to a user group. Watsonx.ai as a SaaS deployment, the external access management system supports IBM Cloud Identity and Access Management (IAM). IAM makes it possible to securely authenticate users for platform services and control access to resources consistently across the IBM Cloud.In addition, watsonx.governance offers monitoring for models and LLM use cases over the lifecycle, a model inventory with all current KPIs of the model and summaries of the training data, as well as dashboards for risk management and individual workflows that define, for example, when models are released for deployments. This can improve the performance of the use of LLMs.  Watsonx does not use feedback loops based on customer data and prompts to further develop models. Customer data is never used for the training of models, unless the customer explicitly wants to do so, for example in the course of prompt or fine-tuning. The enhanced model is only available to the customer and is not used by IBM or other customers. The customer has control over the input and output data when using models. IBM doesn't have access to it. The only exception is that the customer can choose to provide IBM with feedback on the output data. In this case, IBM has access to the output data to improve products and services. However, the customer retains full control over whether or not to submit the output data to IBM. . Our SW platform watsonx and, if applicable, other products are usually provided in German, English, Portuguese, Chinese (traditional & simplified), French, Italian, Japanese, Korean, Spanish and Swedish. The possible uses of the respective LLM for different languages are determined by the training dataset of the respective model. Due to the fact that watsonx supports IBM models as well as open source models, there is currently a large selection of models, and there are no restrictions due to the future possibility of BYOM deployment. For German language, good results are currently being achieved with Llama 2, in March 2024 Granite.13b.multilingual will be available as an IBM model that has been explicitly trained with German, Spanish, Portuguese and French in addition to English and supports them*.IBM Cloud offers a variety of services that support multi-tenancy, including IBM Cloud Kubernetes Service, IBM Cloud Foundry, and IBM Cloud Functions. These services are designed to provide a secure and scalable environment for running multi-tenant applications. Each tenant's data is isolated from and invisible to the other tenants sharing the application instance, ensuring data security and protection for all tenants.  Even for watsonx.ai as locally deployable OnPremise SW, there are various possibilities for multi-tenant capability at different levels in the architecture. Tenants can be clearly isolated by (1) separate projects with separate access rights, (2) separate deployment spaces, and (3) separate name spaces in Red Hat OpenShift.Red Hat OpenShift allows you to update existing running applications through rolling updates. This feature, which is built into Kubernetes, means that you can launch a different version of an application – whether new or older – than the current one, and the traffic will be automatically routed to it. The flexibility and efficiency of Red Hat OpenShift helps keep applications up-to-date and running smoothly.The Red Hat Advanced Cluster Management for Kubernetes management solution, which runs on Red Hat OpenShift, includes capabilities that unify multi-cluster management, provide policy-based governance, and extend application lifecycle management. As a prerequisite, access to the various networks or network areas is necessary or a separate ACM instance can be set up for instances in capped networks.The watsonx documentation lists current limitations and known bugs. Left: - Current limitations: https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/known-issues.html?context=wx - Known Issues: https://www.ibm.com/docs/en/watsonx-as-a-service?topic=overview-known-issues-limitations - Support Library and Knowledgebase: https://www.ibm.com/mysupport/s/ibm-community-support-search-results - SaaS and software documentation: https://www.ibm.com/docs/en/watsonx-as-a-service see also point 3.4.the deployment is based on Kubernetes with Red Hat OpenShift, see point 5.3.The watsonx .ai platform provides powerful and flexible solutions through the use of Kubernetes, based on the renowned Red Hat OpenShift container platform. In addition, our customers benefit from the seamless integration of the powerful IBM Spectrum Fusion HCI, delivered directly with the Red Hat OpenShift container platform. The hardware requirements for watsonx are highly dependent on the models used and the number of users and replicas required. An example configuration for watsonx.ai as software with 8 GPUs would be as follows. - These 8 GPUs can be assigned in one of the following ways: o 8 small/medium model instances (e.g. Granite v2, not Lama2-70b-chat), each requiring 1 GPU1 Lama2-70b chat model instance (4 GPUs required) + 4 small/medium model instances (1 GPU required each) o 2 Llama2-70b chat model instances (each requiring 4 GPUs) o The documentation shows a detailed overview with the hardware requirements of the models here: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=setup-adding-foundation-models - Support for up to 250 concurrent users in the Prompt Lab 5 active deployments of machine learning models - 10 active JupyterLab or notebook environments The hardware required is the following: - 8 A100 80GB GPUs - 64 virtual CPUs - 1045 GB Memory - Approx. 2TB storage, supported: Red Hat OpenShift Data Foundation storage, Portworx storage, NFS storage see documentation: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=watsonxai-installing. all watsonx modules will be offered as locally deployable software in addition to a SaaS variant. Both installation and operation can be air-gapped. The modules watsonx.ai and watsonx.data are already available locally deployable, watsonx.governance locally is planned for Q1 2024 on the roadmap*. See below links:  Leverage Secure Gateway to secure connection between env and cloudSecure Architecture best practicesIBM Cloud Hyper protect crypto services to fully manage encryption keys and to perform cryptographic operationsWatson Security architecture describes the security components that are needed for secure cloud development, deployment, and operations.IBM Cloud compliance programs describe how to manage regulatory compliance and internal governance requirements with IBM Cloud services. Learn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey at Data Responsibility GDPR. US Health Insurance Portability and Accountability Act (HIPAA) support is available for Enterprise plans that are hosted in the Washington, DC or Dallas locations. For more information, see Enabling HIPAA support for your account.Do not add personal health information (PHI) to the training data (entities and intents, including user examples) that you create. In particular, be sure to remove any PHI from files that contain real user utterances that you upload to mine for intent or intent user example recommendations.  All Internet facing websites must be protected by web application firewall (WAF) solution.  The IBM Cloud solution utilizes a WAF from CloudFlare.Strong physical controls in data centers including secondary data centres and backup copiesIBM Cloud data centers are run by a separate organization, with no physical access possible by anyone outside the team, including product and development teams. Availability of the solution, including both internal and customer data is made available via a multi-zone and multi-zone-region concept. More information about IBM Cloud datacenters is available here: https://www.ibm.com/cloud/data-centers. Soc1/2 Requested:  Security Report Requests - Intake Form (ibm.com).There are none, per section 8 of the Data Processing and Protection Datasheet. Services are deployed and available on several data centers with multiple zone routing (MZR) on three availability zones. At any time, if one zone becomes available for any reason, the system continues to be available in two other availability zones within that data center. The global-load balancer and DNS server routes traffic to available zones without any user interruption.https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime.  The IBM Data Processing Addendum (DPA) at http://www.ibm.com/dpa applies to the Processing of Personal Data by IBM on behalf of Client under the Agreement in order to provide and improve the IBM Services and other IBM services that utilize the same underlying technology or tools, and as otherwise set out in the Agreement, if and to the extent i) the European General Data Protection Regulation (EU/2016/679) (GDPR); or ii) any other data protection laws identified below apply.Other documents related to the Cloud service including Data Security and Privacy(DSP) and Cloud Service Agreement (CSA and Service Description(SD) can be searched at:  IBM Terms . for Watson Studio and Watson ML services with a non disclosure in place between our companies . When you create a project or deployment space, you specify a IBM Cloud Object Storage and create a bucket that is dedicated to that workspace. These types of objects are stored in the IBM Cloud Object Storage bucket for the workspace:    -Files for data assets that you uploaded into the workspace. -Files associated with assets that run in tools, such as, notebooks and models--Metadata about assets, such as the asset type, format, and tags..IBM Cloud Object Storage, then,  provides resiliency against outages. IBM watsonx provides network security mechanisms to protect infrastructure, data, and applications from potential threats and unauthorized access. Network security mechanisms provide secure connections to data sources and control traffic across both the public internet and internal networks.  Connections require valid credentials to access data. The account owner or administrator configures the type of credentials that are required, either shared or personal, at the account level. Shared credentials make the data source and its credentials accessible to all collaborators in the project. Personal credentials require each collaborator to provide their own credentials to use the data source.Customers can see the events for actions for your provisioned services in the IBM Cloud Activity Tracker. Customer can use the information that is registered through the IBM Cloud Activity Tracker service to identify security incidents, detect unauthorized access, and comply with regulatory and internal auditing requirements.  Specifically, refer following for more details about Network Security : https://www.ibm.com/docs/en/watsonx-as-a-service?topic=security-network#connections.It will not be used to improve IBM models.  Client data remains theirs and will be treated no different than any other Content uploaded into any IBM Cloud Service.We do not store any data input to our models.  The inferencing API itself uses HTTPs and hence the data is encrypted on the wire.The user controls the data retention of the inputs and outputs.  IBM doesn’t have access to them.  The one exception is the customer can elect to provide IBM feedback on output, and in that case IBM retains the output to improve products and services.  Customer retains full control over whether they submit the output to IBM or not.In watsonx.ai, client is engaging with a frozen version or instance of the model.  Client’s data is not engaging with a model that is actively learning in a broad community setting.The same as any other Client Content stored in the cloud.The same as any other Client Content stored in the cloud.The same as any other Client Content stored in the cloud. CPDaaS is deployed and available on several data centers with multiple zone routing (MZR) on three availability zones. At any time, if one zone becomes available for any reason, the system continues to be available in two other availability zones within that data center. The global-load balancer and DNS server routes traffic to available zones without any user interruption.https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime. The IBM Data Processing Addendum (DPA) at http://www.ibm.com/dpa applies to the Processing of Personal Data by IBM on behalf of Client under the Agreement in order to provide and improve the IBM Services and other IBM services that utilize the same underlying technology or tools, and as otherwise set out in the Agreement, if and to the extent i) the European General Data Protection Regulation (EU/2016/679) (GDPR); or ii) any other data protection laws identified below apply.watsonx. governance will support CMoR Model Risk validation by providing automation for collecting, displaying and reporting data on all phases of the models' lifecycles.  . Based on our understanding of entitlements, we can support enforcement.  . IBM does vulnerability scanning, detection and remediation.  The watsonx platform provides services to perform data privacy based on user defined criteria. IBM does not have access to or make use of customer data.  https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/security-data.html?context=wx&audience=wdp. with watsonx as a local on-premise software or Public Cloud Provider deployment, one key can be used per tenant if the tenants are separated at the namespace level. The watsonx platform is available as a SaaS solution and on Cloud IaaS. The hardware requirements for watsonx are highly dependent on the models used and the number of users and replicas required. An example configuration for watsonx.ai as software with 8 GPUs would be as follows. - These 8 GPUs can be assigned in one of the following ways: o 8 small/medium model instances (e.g. Granite v2, not Lama2-70b-chat), each requiring 1 GPU1 Lama2-70b chat model instance (4 GPUs required) + 4 small/medium model instances (1 GPU required each) o 2 Llama2-70b chat model instances (each requiring 4 GPUs) o The documentation shows a detailed overview with the hardware requirements of the models here: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=setup-adding-foundation-models - Support for up to 250 concurrent users in the Prompt Lab5 active deployments of machine learning models - 10 active JupyterLab or notebook environments The hardware required is the following: - 8 A100 80GB GPUs - 64 virtual CPUs - 1045 GB Memory - Approx. 2TB storage, supported: Red Hat OpenShift Data Foundation storage, Portworx storage, NFS storage see documentation: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=watsonxai-installing. Please refer to CPU specs item above.Please refer to CPU specs item above. The platform will support efficient compilers and runtime accelerators.The platform supports any network speed that is in place.the product requires local storage on openshift nodes.Please refer to CPU specs item above. The plaform support Intel based systems.The product does not provide object storage, Can use platfrom connections to connect to data sources outside the cluster https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=tasks-setting-up-platform-connections.The watsonx .ai platform provides powerful and flexible solutions through the use of Kubernetes, based on the renowned Red Hat OpenShift container platform.The deployment is based on Kubernetes with Red Hat OpenShift. In IBM Support you will find detailed data on the release cycles of the respective software products. Products in the context of generative AI are in a volatile environment. At watsonx, for example, the initial version (v 1.0.0) was available in July 2023 and the first minor release (v 1.1.0) in November 2023, see here: https://www.ibm.com/support/pages/lifecycle/search?q=watsonx IBM distinguishes between three types of releases: 1. Major releases: Approximately every 2 years, involve significant changes and may require migration. Example: 2.0.0 2. Minor releases: About twice a year, contain new features, do not reset support cycle. Example: 2.5.0 3. Monthly updates: Every month, bug and security fixes only. Example: 2.0.1 Minor releases do not reset the support cycle and expire at the same time as major releases. As a rule, all versions that are less than 2 years old are supported.. you can use scale feature from the platform to scale the services.In the roadmap.we can scale the training deployment, to have more instances to handle training.have HPA supported out of the box.Workloads are deployed in nodes that have compute available and are scheduled through openshift.We have namespace quotas available to restrict workloads, jobs are priorotized on first come first serve.the product provide a GUI for a Landing Page / dashboard.the platform provide Jupyter Notebook capability. Jupyter notebooks can be easily attached to resources - CPU / GPU / Memory / StorageDocumentation SaaS: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/notebook-environments.html?context=wx&audience=wdp#runtime-scopeDocumentation Software: https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=environments-notebook. Users can easily manager resources from a GUI. But does not support auto scaling. wastsonx supports multiple frameworks.https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/notebook-environments.html?context=wx&audience=wdp#types.  Watsonx has integrated with LangChain as an LLM provider, which enables external infrastructure solutions such as vector stores, embedding services, and others to be seamlessly and consistently incorporated into common LLMOps orchestration practices.https://python.langchain.com/docs/integrations/llms/ibm_watsonx/. watsonx provides GUI for Landing Page / dashboard.the platform provides Jupyter Notebook capability.Jupyter notebooks can easily be attached to resources - CPU / Memory / Storage.Users can easily manager resources from a GUI. But does not support auto scaling. wastsonx supports multiple frameworks.https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/notebook-environments.html?context=wx&audience=wdp#types. Securing your Cloud Pak for Data environment - IBM Documentation.watsonx supports SSO for APIs.watsonx supports security control access to User by Group level authentication against Active Directory (Azure AD).watonx supports Authorization using RBAC.watsonx supports multi-tenancy.Key management by application:  https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=encryption-key-management-by-application.watsonx has the ability to encrypt data at rest and transit.Data can be masked if Knowledge Catalog is part of deployment:  https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=data-masking-masking-flow.IBM does not have access to customer data.the Data Pipeline is hosted On-prem and SaaS. Hardware requirements https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=requirements-hardware.Storage requirements https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=requirements-storage.  One of the following types of GPUs is required to support the use of foundation models in IBM watsonx.ai:NVIDIA A100 80 GBNVIDIA H100 80 GBNVIDIA L40S 48 GBhttps://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=setup-adding-foundation-models. Storage requirements depend on the LLM https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=setup-adding-foundation-models.watsonx is installed into RHOS which is an implementation of K8 https://developer.ibm.com/articles/awb-the-open-source-ecosystem-of-watsonx/.watsonx runs in RHOS, which includes RH Linux OS https://docs.openshift.com/container-platform/4.12/architecture/architecture-installation.html.The IBM Solution is built on top of Red Hat OpenShift. You can leverage OpenShift’s built-in troubleshooting tools to inspect logs from pods and troubleshoot issues within containerized services.  .The IBM Solution is built on top of Red Hat OpenShift. You can leverage OpenShift’s built-in troubleshooting tools to inspect logs from pods and troubleshoot issues within containerized services.  .The IBM Solution integrates with IBM observability toolset which implements collection and monitoring of the entire observability context – from topology and tracing, through monitoring and logging. The Observability platform is designed to be user-friendly for various teams, including developers, .The IBM Solution utilizes a combination of pre-configured options and customizable settings to send alerts about your system’s health and performance .  It comes with default alert rules that monitor various system aspects.  You can choose where you want to receive alerts. The solutions supports sending them via email (using SMTP), Slack, or an SNMP server.The IBM Solution is built on top of Red Hat OpenShift. You can leverage OpenShift’s built-in troubleshooting tools to inspect logs from pods and troubleshoot issues within containerized services.  Additionally, the solution can be integrated integration with external tools like IBM  observability toolset.  These comprehensive observability platforms provide deeper insights into application performance, infrastructure health, and resource utilization that support troubleshooting processes.Users can track different versions and approaches under a use case across lifecycle. Enhanced Experiment tracking is currently planned as a 2H 2024 roadmap item for watsonx.governance. . watsonx.governance includes several out-of-the-box metrics for quality such as:Area under ROC, Area under PR, Area under ROC, Area under PR, Accuracy, True positive rate, False positive rate, Recall,Precision, F1-Measure, Logarithmic loss, Proportion explained variance, Mean absolute errorMean-squared error, R-squared, Root of mean squared error, Weighted true positive rate,Weighted false positive rate, Weighted recall, Weighted precision, Weighted F1-Measure, Matthews correlation coefficient, Label skew;  Fairness; Output drift, Model quality drift, Feature drift, Prediction drift, Input metadata drift, Output metadata drift. ROUGE, SARI, METEOR, Text quality, BLEU, Sentence similarity, PII, HAP, Readability, Exact match, Multi-label/class metrics, source attribution.  In addition, users can add custom metrics.  - Scoring requests- Total records- Average records- Minimum, maximum, median records- For LLMs:  total, average, minimum, maximum, and median input token countsFor LLMs:  total, average, minimum, maximum, and median output token counts - API latency- API throughput- Record latency- Record throughput- Number of users sending scoring request- For Machine Leaning:  total, average, minimum, maximum, and median payload size of the transaction records that your model deployment processes across scoring requests in kilobytes (KB).  Metrics are computed and stored in a Datamart. Through payload logging in the Datamart that needs to be configured with watsonx.governance evaluation/monitoring capability. .metrics are captured at build, test/validate, and can be setup for continous monitoring in production also. .The platform supports integration with DataStage and Databand for data ingestion and monitoring. Model health monitor evaluations in watsonx.governance to understand model performance. Out-of-the-box, for the   model health   metrics group, the following is supported out-of-the-box: - Scoring requests- Total records- Average records- Minimum, maximum, median records- For LLMs:  total, average, minimum, maximum, and median input token countsFor LLMs:  total, average, minimum, maximum, and median output token counts - API latency- API throughput- Record latency- Record throughput- Number of users sending scoring request- For Machine Leaning:  total, average, minimum, maximum, and median payload size of the transaction records that your model deployment processes across scoring requests in kilobytes (KB).https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=evaluations-configuring-model-health-monitor. watsonx.governace Governance Console and Evaluations dashboard to capture different models, use cases, risk, metrics, and other elements for ML and LLM use cases.watsonx.governance alerts can be sent to email, slack, or configured via WebHooks to other systems. .If the question pertains to implementing a company's standards and best practices, then workflows in Governance Console of watsonx.governance can assist with that. .If the question is about end-users following governance processes, then workflows and issue management capabilities in watsonx.governance Governance Console can assist in providing accountability.  . Model health monitor evaluations in watsonx.governance to understand model performance. Out-of-the-box, for the   model health   metrics group, the following is supported out-of-the-box: - Scoring requests- Total records- Average records- Minimum, maximum, median records- For LLMs:  total, average, minimum, maximum, and median input token countsFor LLMs:  total, average, minimum, maximum, and median output token counts - API latency- API throughput- Record latency- Record throughput- Number of users sending scoring request- For Machine Leaning:  total, average, minimum, maximum, and median payload size of the transaction records that your model deployment processes across scoring requests in kilobytes (KB).https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=evaluations-configuring-model-health-monitor.  IBM has 4 enterprise-ready support options and multiple channels for ensuring worldwide, around-the-clock support to help its global client base troubleshoot:0. Product documentation - IBM watsonx has robust technical documentatoin to guide users on how to effectively leverage the platform1. IBM Support Site - A self-serve, cognitive platform that allows customers to search support documentation and open support tickets.  Articles and documentation are available in multiple languages.  Available for free to all clients.2. IBM Base Support - Provides additional benefits such as preventive support via fixes and updates, production support via 24/7 access to skilled support professionals, cognitive capabilities delivered by IBM Watson, and support via phone.3. IBM Advanced Support - Provides additional benefits for a fee relative to Base, such as faster response times, higher support case prioritization, and priority access to senior technical support professionals. Mutually agreed Critical Severity 2's will be worked 24x7 if Customer agrees to work 24x7 and Single Software Support Executive Sponsor for Hyper-care situations4. IBM Expertise Connect - Helps clients optimize their IBM technology by providing access to dedicated, skilled IBM technical resources: includes a dedicated technical account manager, proactive technical guidance & best practices, and on-demand collaboration and assistance with architecture reviews, health checks, performance optimizations, upgrades, and migrationsThe above information and additional details can be found on our support page: https://www.ibm.com/support/pages/node/795690. IBM watsonx is a commercial platform that providers users with access to both proprietary, open source, and 3rd party models. Watsonx offers two licensing models:Watsonx SaaS: A software-as-a-service (SaaS) model that provides access to Watsonx functionality on a subscription basis.Watsonx On-Premises: An on-premises model that allows customers to deploy Watsonx on their own infrastructure, with a perpetual license or subscription option. watsonx has the ability to terminate jobs/processes Through IBM Tel Services.IBM provides various training resources, including online courses, tutorials, and documentation. .Whether you are running a solution with IBM Cloud services, on-premises software, systems, appliances, hybrid environments, or non-IBM products, IBM Support is enterprise-ready and flexible - available around the clock and around the world - to help you keep your cognitive businesses running smoothly. Our support options are categorized at the following link: https://www.ibm.com/support/pages/node/795690. watsonx.ai than OnPremise software can use SAML (Security Assertion Markup Language), SSO (single-sign-on) and LDAP (Lightweight Directory Access Protocol) together or individually. An enterprise-grade LDAP password management provider can be used. Users can be added manually, individual LDAP users can be included by adding them to a user group, or access can be granted to all members of an LDAP group by adding an LDAP group to a user group. Watsonx.ai as a SaaS deployment, the external access management system supports IBM Cloud Identity and Access Management (IAM). IAM makes it possible to securely authenticate users for platform services and control access to resources consistently across the IBM Cloud.In addition, watsonx.governance offers monitoring for models and LLM use cases over the lifecycle, a model inventory with all current KPIs of the model and summaries of the training data, as well as dashboards for risk management and individual workflows that define, for example, when models are released for deployments. This can improve the performance of the use of LLMs.  In IBM Support you will find detailed data on the release cycles of the respective software products. Products in the context of generative AI are in a volatile environment. At watsonx, for example, the initial version (v 1.0.0) was available in July 2023 and the first minor release (v 1.1.0) in November 2023, see here: https://www.ibm.com/support/pages/lifecycle/search?q=watsonx IBM distinguishes between three types of releases: 1. Major releases: Approximately every 2 years, involve significant changes and may require migration. Example: 2.0.0 2. Minor releases: About twice a year, contain new features, do not reset support cycle. Example: 2.5.0 3. Monthly updates: Every month, bug and security fixes only. Example: 2.0.1 Minor releases do not reset the support cycle and expire at the same time as major releases. As a rule, all versions that are less than 2 years old are supported. .  Resource usage is readily visible to users.watsonx has the ability to terminate jobs/processeswith watsonx as a local on-premise software deployment, one key can be used per tenant if the tenants are separated at the namespace level. In SaaS deployments, this can be implemented by designing the environment(s) accordingly. In this way, different projects, deployments or storage pools can be defined for each client, each with its own encryption.watsonx can operate without a connection to the Internet (i.e. Air Gapped)watsonx providers users with 3 different prompt experiences: chat, structured, and freeform.   The chat tab in the Prompt Lab interface allows user to select any model from the library and then chat with it via an interface that is very similar to other chat applications in the market. .encryption is not necessary if the sole intent is to prevent system administrators from seeing the content. System admins don’t actually have access to projects unless they are project members. Only project members can see project content. In fact, encryption is counter-indicated if that is the ask because while there is support for “bring your own keys” in projects, this is done by admins that share their object storage instances and optionally provide encryption keys for the content.in SaaS, Stored chat sessions (beyond non-sensitive metadata) are stored in customer’s own Cloud Object Storage bucket providing project storage. It is possible to define IBM KeyEncrypt root key to be used to encrypt files in the COS bucket and thus encrypt all the chat sessions.subject to file size and format limitations. Starting Q3 24, users will be able to upload files into projects and use them to ground models while using the “chat” tab in the Prompt Lab or for their RAG applications. Users will also be able to upload those files into either watsonx.data Milvus or Elasticsearch vector stores for a more scalable, Enterprise-ready RAG solution. .files are protected by using platform users and access control features.watsonx has a foundation  model library with numerous hosted models to select from for inference. Clients can also import their own foundation models as long as the architecture is supported by watsonx, once imported and hosted, those models will also appear in the library and API for use. .all assets such as datasets, prompts, notebooks, models are stored in a  project  which has easy navigation to select, view, open and set access permissions for any project assets. As well as options to import or add new assets. .watsonx users can save all work to a project and assign access to those assets to other users in the account. . watsonx.ai than OnPremise software can use SAML (Security Assertion Markup Language), SSO (single-sign-on) and LDAP (Lightweight Directory Access Protocol) together or individually. An enterprise-grade LDAP password management provider can be used. Users can be added manually, individual LDAP users can be included by adding them to a user group, or access can be granted to all members of an LDAP group by adding an LDAP group to a user group. Watsonx.ai as a SaaS deployment, the external access management system supports IBM Cloud Identity and Access Management (IAM). IAM makes it possible to securely authenticate users for platform services and control access to resources consistently across the IBM Cloud.In addition, watsonx.governance offers monitoring for models and LLM use cases over the lifecycle, a model inventory with all current KPIs of the model and summaries of the training data, as well as dashboards for risk management and individual workflows that define, for example, when models are released for deployments. This can improve the performance of the use of LLMs. The IBM solution component Watson Assistant can be used to integrate with MS Teams and SLACK. .Accessibility is a core component of our UXUI design process and watsonx meets IBM's accessibility standard.  . Many videos with voice are included in support of understanding and quick up and running. https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=tutorials-quick-starthttps://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x?topic=tutorials-use-caseVideo library - IBM Documentation. The design of the UI is such to be inclusive of a broad secure access to set of user roles including data scientists, business analysts, developers, and GenAI enabled businesss users.   In addition via API access, applications can interact with watsonx.ai capabilities. Watsonx platform has data versioning through the native iceberg table support.  Users can leverage time-travel queries to query and restore data that was updated or deleted in the past. Or they can roll back a table to any existing snapshot. Watsonx provides data lineage capabilities via the internal meta datastore used to keep track of information about the data in your databases.  Watsonx also has built-in features that leverage an Enterprise Data Fabric architecture with integration to IBM’s Knowledge Catalog (IKC).  This includes data lineage which is automatically captured throughout the data lifecycle. Specifically, through an integration with Manta, IKC allows customers to automatically import lineage metadata from 50+ 3rd party technologies including databases, ETL, BI, etc. Customers can view the lineage in the context of their cataloged assets with the ability to drill into technical metadata like column level lineage and historical lineage.Also, IBM has acquired Manta to further enhance data lineage capabilities.   Learn more:  https://newsroom.ibm.com/IBM-acquires-Manta-Software-Inc-to-complement-data-and-AI-governance-capabilities. Watsonx Synthetic Data Generator provides an intuitive graphical editor that allows users to quickly generate synthetic tabular data based on production data or a custom data schema using visual flows and modeling algorithms. .Watsonx has notebook capabilities, visual data flows, Auto AI where features can be created, evaluated and transformed to fit ML processing.Watsonx has notebook capabilities, visual data flows and a data refinery where data can be ingested, analyzed and manipulated to fit the ML process.  Also, Auto AI will apply certain functions to impute, encode or scale data as needed.Watsonx has an Auto AI feature which will automatically explore feature sets and rank them for optimization.Watsonx has an Auto AI feature that will evaluate and select features for a given ML optimization objective.Watsonx has an Auto AI feature that will evaluate and select features for a given ML optimization objective.Watsonx software has a feature to identify and preserve a set of columns of a data asset along with associated metadata for use with Machine Learning models. Feature groups can be published to IBM Knowledge Catalog so that it can be used as a feature store.Watsonx includes capability to evaluate model fairness – both direct and indirect bias - during model training and validation and once it is deployed. These fairness evaluations generates a set of 9 out-of-the-box metrics hourly but can also be generated on-demand.  Users can specify thresholds and be alerted when these thresholds are breached. Furthermore, it helps mitigate bias through active and passive de-biasing. Passive de-biasing is automated, regularly monitored, and happens without user intervention. The platform analyzes the model behavior, identifies the data where the model outcome is biased, and de-biases the data. Active-debiasing provides the ability to invoke on demand the ability to understand the debiased prediction of your model and decide to accept the recommendations saving manual data scientist time.  Lastly, watsonx Auto AI can evaluate an experiment for fairness to ensure that results are not biased in favor of one group over another.Automated model training (autoML).Workflow templates.Model and experiment tracking (enterprise-wide).Proprietary ML algorithms (vs open-source).Integration with open-source ML algorithms / frameworks.Model Hyperparameter Tuning.Model Assessment.Model Optimization.Bias detection and mitigation capabilities.Watsonx provides a programming interfaces such as Notebooks, APIs, SDKs and IDEs such as Jupyter, RStudio and VSCode.Watsonx platform is predominantly designed with drag and drop or  single click  interfaces for most major features.Watsonx provides seamless collaboration and workflows that allow multi-persona teams to share project assets such as data, models, pipelines, experiments.   It also includes out-of-the-box workflows or flows that can be easily built in a drag-drop interface while offering flexibility on different logic, alerting, users for oversight. These workflows are also re-usable across other use cases.Watsonx provides an Auto AI feature that will analyze data and provide recommended models.Watsonx provides sample notebooks for all major features. The platform also provides sample templates to help users get started with just about any type of use case.Watsonx provides numerous features to prepare (build), test, validate, deploy and monitor models.  .watsonx includes comprehensive AI governance including lifecycle tracking and automated model metadata capture, evaluation and monitoring throughout lifecycle, as well as risk management and compliance capabilities. These capabilities can be consumed in a modular fashion and the UI and designed with a broad range of users in mind spanning data scientists, model validators, risk & compliance focals etc;. .watsonx includes out-of-the-box risk workflows and risk assessment methodology, including questionnaires on regulatory compliance applicability (e.g. EU AI Act) and AI risk identification.  It also includes pre-loaded Risk Dimensions based on IBM Research and IBM AI ethics findings that are automatically assigned based on Risk questionnaire responses.  In addition, quality, drift, performance, and any other custom metrics that users are monitoring for their models are also synced and reflected in a visual Governance Console. Lastly, these capabilities can be easily configured or adapted to the clients' AI governance needs. .watsonx includes Model Risk Governance integrated with both Operational Risk Management and Regulatory Compliance Management capabilites in an Enterprise Governance, Risk, and Compliance solution to enable holistic risk management in enterprises. .Watsonx platform has the ability to monitor and track account resource usage to ensure limits are not exceeded. This helps administrators to optimize or manage cost on various workloads and its runtimes.A generative AI model used to create high fidelity synthetic tabular data within the watsonx.ai product. This is planned for GA in Q4 of 2024 with existing previews and POCs being done by clients. .Watsonx supports prompt engineering against foundation models. It allows model parameters settings to be customized as well as prompt variables. There are optional guardrails to filter out hate, abuse and profanity from prompt input and the model output. Prompts developed in the Prompt Lab can be saved to projects as assets or templates and shared with others as well as saved as notebooks for use with the API. Prompt templates can be tracked in the platform where meta data is automatically collected to understand history and usage. There is also a feature to apply parameter efficient fine tuning to tune and optimize foundation models. The platform provides numerous notebooks that can be used to create RAG use cases.  The platform currently does not support training a base foundation model from scratch. However, users can import a foundation model if the base architecture is supported.Yes. Watsonx.ai empowers data scientists, developers, and analysts to build, run, and manage AI models—bringing traditional AI and generative AI into production, faster. Build models either visually or with code, and deploy and monitor into production. With MLOps you can simplify model production from any tool and provide automatic model retraining.Our software allows you to have a no code functionality via allowing you to update the MLops pipeline using the UI or you can also use the APIs SDK to update that via code.Yes, There are options to drag and down various buttons and create workflows. .Yes, It is quite a seamless platform that could be used by both the set of users. . Watsonx software has a collection of supporting components. After the software and components are downloaded, client is required to run an CLI installer command which informs the installer about license entitlements. Upon installation, clients can use the command line to specify which components and foundation models they need to install that support their use case and environment. A typical installation could take 2- 3 hour to complete including any necessary models.. The current software version of watsonx requires IBM Cloud Pak for Data and Red Hat Openshift components to be installed.   The client also must have sufficient GPU's to process the foundation models they intend to use for their use cases. .IBM follows a continuous delivery practice for watonx releases.  On average, there are 3 releases per month across our SaaS and Software versions.  .Software updates are posted to the IBM software download site where existing clients can retrieve them and apply to their existing install base. .Yes, the platform includes error and warning messages with links to details that assist with troubleshooting.Yes, the platform has readily available usage reports within the watsonx project console. There is also audit logging capabilities that track usage of the product. .Automated PII identification.Automated PII redaction.Data Masking. Watsonx platform supports autoscaling of data, training and inference workloads. Deployment spaces on watsonx supports services to build, train and deploy foundation and machine learning models at scale; and a data platform to securely store structured and unstructured data, anywhere, with scalability, resilience and security.  Watsonx data, training and inference services are built on a scalable, open source platform based on Kubernetes and Docker components and can be deployed as a microservice that can autoscale.For optimizing workloads, a multi-tenant queue based system is used with an adjustable number of worker nodes. Both single and multi GPU fine-tuning and prompt-tuning jobs can be run concurrently based on the workload to optimize throughput and minimize latency.  Watsonx SaaS platform leverages a variety of GPU Types to match workload requirements with cost-effective hardware.  Also, the platform’s flexible deployment capabilities brings workloads closer to data which improves latency.For optimizing model inference, IBM has designed its foundation model library with a focus on smaller, domain or task-specific LLMs that required much lower compute and provide lower response latency.  Also, models can be deployed with a multi-pod deployment allowing more GPU resources to be used for a single model in case of high load. Requests from single or multiple users are dealt with concurrently in an optimized batch manner through the use of TGI or vLLM based model runtimes.  Quantization of models reduces memory footprint using lower precision weights to allow models to run on fewer GPUs, cutting costs and improving hardware utilization.. Watsonx has an easy to use, highly consumable UI promoting AI Usage across a broad range of roles including data scientists, developers, LOB / Application developers and business users.  In terms of process, the watsonx platform allows teams to follow a consistent pattern for managing project assets and the AI lifecycle. Watsonx also has governance capabilities with custom model monitoring metrics that a client can setup to adhere to their internal standards. Watsonx platform offers a robust monitoring solution for machine learning and general AI models. It equips users with tools to configure monitors that assess deployed assets based on fairness, explainability, drift, and transparency criteria, all of which can be tailored to the specific needs of your organization. A Model Health monitor is also included, offering real-time performance tracking for your deployed models. This feature allows organizations to maintain optimal performance levels and ensure their AI models remain unbiased, transparent, and effective over time. By continuously monitoring these aspects and alerting organizations to risk, Watsonx platform helps businesses build trust in their AI systems and make data-driven decisions with confidence.. Watsonx platform supports scaling of resources manually in deployment space by increasing the number of copies created for your deployment. as well as automatically by using the Red Hat OpenShift Horizontal Pod Autoscaler (HPA) especially for data. The HPA changes the resource allocation of components by increasing or decreasing the number of pods in response to CPU or memory consumption.Watsonx platform is built on top of a strong data fabric architected data platform that helps you scale enterprise AI and Analytics. The data platform supports open formats to access all your data through a single point of entry and share a single copy of data across your organisation and workloads without needing to migrate or recatalog. This includes fit for purpose query engines, integrated vector database,  embeddable AI powered semantic layer, integration with databases, tools and modern data stacks with the help of connectors and hybrid deployment options to deploy across any cloud or on-premises environments. Watsonx platform has lot of inbuilt BI and data visualization tools like Data Refinery and data visualizations.The platform is also integrated with Cognos Analytics an AI-powered automation and insights application. Cognos Analytics brings in new generation of BI with AI capabilities that not only bring an accurate, trusted and complete picture of your business, but forecast what’s coming in the future, predict outcomes and explain why they may happen. Watsonx platform allows to organise your assets in a collaborative workspace called Projects. The platform allows customers to link a project to a GitHub repository. To collaborate with stakeholders and other data scientists, users can publish notebooks in GitHub repositories. Users can also use GitHub to back up notebooks for source code management. .Watsonx platform supports seamless integration with various open source MLOps tools like MLflow, Jenkins, Bamboo, docker registry etc. Watsonx platform is built on top of a strong data fabric architected data platform that helps you scale enterprise AI and Analytics. The data platform supports open formats to access all your data through a single point of entry and share a single copy of data across your organisation and workloads without needing to migrate or recatalog. This includes fit for purpose query engines, integrated vector database,  embeddable AI powered semantic layer, integration with databases, tools and modern data stacks with the help of connectors and hybrid deployment options to deploy across any cloud or on-premises environments.Watsonx platform supports Orchestration pipelines which is built on Elyra canvas to make it easy to run notebooks or scripts as batch jobs, and, therefore, automate common repetitive tasks. Elyra Canvas is an open-source library, which provides React objects that enable applications to quickly create a fully functional flow editor. Users can easily create and edit the flows of linked nodes by using the flow editor.The platform also supports integrating with GUI-driven approach to creating Apache Airflow workflows that implement machine learning pipelines using Jupyter Notebooks and Python scripts. Watsonx platform supports monitoring of AI and ML models deployed for batch inferencing with the help of a seamlessly integrated Governance offering with Open Scale and AI Factsheet. This capability can prepare test data and monitor machine learning and GenAI models to meet governance and compliance goals.Watsonx platform supports monitoring of machine learning and AI models that take in text streams as inputs with the help of a seamlessly integrated Governance offering with Open Scale and AI Factsheet. This capability can prepare test data and monitor machine learning and GenAI models to meet governance and compliance goals.Watsonx platform includes RStudio, an integrated development environment for working with RScripts. Users can build web applications using R Shiny using R programming language. This enables users to quickly build interactive and data driven web applications without extensive knowledge of web application.Watsonx platform supports integration with Orchestrate tooling that supports rule-based decision modeling for automation.Watsonx platform supports a seamless integration with a comprehensive ML/AI governance platform called Watsonx Governance with feature rich monitoring and reporting. It supports managing enterprise risk and compliance with Governance Console which is an integrated governance, risk and compliance (GRC) suite that customers can use to identify, manage, monitor and report on risk and compliance initiatives that span the enterprise. With Governance Console, you can collect metadata about foundation models and machine learning models to help you achieve your governance goals. This suite can also be used to develop workflows that support your governance processes. This platform supports monitoring of LLM specific metrics like accuracy, fairness, quality and drift. .Our pre-built and open APIs allow quick and easy integration with other enterprise systems.The watsonx platform is designed to be flexible and adaptable, catering to organizations regardless of their stage in their general AI journey. The user experience is tailored to both technical and non-technical audiences, with features and functionalities built-in to accommodate a wide range of user personas. Users have the freedom to create custom workflows, dashboards, risk and compliance metrics, thresholds, machine learning frameworks, and reporting templates according to their technical aptitude and user persona. This flexibility enables organizations to tailor the platform to their specific needs and preferences, ensuring a seamless and efficient experience. Watsonx platform supports creation of a feature group to preserve a set of columns of a data asset along with associated metadata for use with Machine Learning models. Feature groups make it simple to preserve the metadata for the features used to train a machine learning model so other data scientists can use the same features. The tool allows users to create, edit, delete and search via GUI or API..  Watsonx includes metrics to monitor for fairness along with active and passive de-biasing.The platform has inbuilt fairness test that provides customers ability to define fairness attribute, monitored and reference groups, favourable and unfavourable outcomes and compute disparate impact and its threshold values. The platform can also automatically identify commonly protected attributes or features that are potential source of bias. The platform supports the following commonly protected attributes -age, citizen status, color, disability, ethnicity, gender, genetic information, handicap, language, marital, political_belief, pregnancy, religion, veteran status. Users can also define protected attributes manually.  Watsonx platform can identify features contribute to the model’s predicted outcome for a transaction and predict what changes would result in a different outcome.  Users can configure local explanations to analyze the impact for specific model transactions and configure global explanations to analyze general factors that impact model outcomes. This feature supports Shapley Additive Explanations and Local Interpretable Model-Agnostic explanations as explanation methods. The service also provides explanations for model transactions to help understand how predictions are determined. It supports explanations for structured, image and unstructured text models. Watsonx.ai provides explainability/benchmarks for models that are onboarded to the platform.  Watsonx platform supports in product model documentation part of model gallery / model card and factsheets.. watsonx includes several out-of-the-box metrics to assess quality and performance during training and validation. It also includes workflows so to complete before a model can be moved to production and issue management in a single place. . Watsonx platform has a model gallery that hosts all the large language models that are onboarded to the platform with model details documented at length. The model registry also hosts all the models that are imported using Bring Your Own Model and users can remove these models on a need basis. Watsonx platform supports automated promotion of trained machine learning models or fine tuned foundation models to the model registry/deployment space with the help of GUI or API or a development environment like notebooks.Watsonx Platform supports deployment of Foundation Model assets like Prompt Template and Tuned Model and Machine Learning Assets like models, python functions/scripts, decision optimization models, PyTorch models, Scikit-learn and XGBoost models, Spark Models, SPSS models, Tensorflow models etc as Online or Batch deployments. Online deployments predict results in real time while a Batch deployment can be used when the input data is large from a file, data connection or connected data. Both no-code via GUI and code approaches can be used to create deployments.Watsonx platform supports tracking of machine learning and generative AI models to meet compliance and governance goals with AI factsheets service. The service supports tracking models that are built on watsonx platform as well as third party tools such as Amazon Web Services, Microsoft Azure, Azure ML Studio, Azure ML Service, AWS Sagemaker or any other supported custom machine learning framework. The platform supports tracking machine learning models or foundation models in a notebook or the details are populated on a GUI called factsheets.Watsonx platform with its OpenScale performance metrics helps users know the velocity of data records processed by a deployment. Any deployment can be tracked and monitored. The performance metrics are calculated based on scoring payload data and logging of every scoring request. Payload data logging is automated and can be provided by using a Python client or by REST API. Openscale supports both drift in model accuracy and drift in data. The platform with its drift detection model helps to generate metrics that determine how the model predicts outcomes over time. The drift evaluations can be viewed on an Insights dashboard.Watsonx platform with its governance service or AI factsheets enables governance and monitoring of models that are created in notebooks or outside of the watsonx platform. It monitors models that are built on watsonx platform as well as third party tools such as Amazon Web Services, Microsoft Azure, Azure ML Studio, Azure ML Service, AWS Sagemaker or any other supported custom machine learning framework. .Watsonx platform from its Projects allows export of Machine Learning Model assets to be exported, deployed and used in any non-IBM third party tools.Watsonx platform with its governance service or Open Scale supports sending of notifications and alerts when a performance metric is outside of the acceptable range specified by configured drift monitors. Watsonx platform support downloading and retraining of machine learning models with compatible with a supported framework from deployment spaces. Updating a model is also supported using an API.Orchestration pipeline with an easy drag and drop user interface can help automate continuous evaluation and retraining of models.  Watsonx platform supports deployment of machine learning models, scripts and functions and prompt templates for generative AI models. Users can choose to deploy these models as an online for real time inferencing, batch when the input is a large batch from a data source or application deployment when you want to deploy assets such as RShiny apps.The platform supports IBM Cloud Connectivity options for accessing cloud services securely by using service endpoints. While provisioning users can choose either to access the service through public internet or over the IBM Cloud private network. Provisioning can be done either via GUI or using a CLI.  In Watsonx Platform when you create an online deployment for a model or function from a deployment space or programmatically, a single copy of the asset is deployed by default. To increase scalability and availability, you can increase the number of copies (replicas) by editing the configuration of the deployment. More copies allow for a larger volume of scoring requests.Deployments can be scaled in the following ways:Update the configuration for a deployment in a deployment space.Programmatically, using the Watson Machine Learning Python client library, or the Watson Machine Learning REST APIs. Watsonx Platform supports deployment of Foundation Model assets like Prompt Template and Tuned Model and Machine Learning Assets like models, python functions/scripts, decision optimization models, PyTorch models, Scikit-learn and XGBoost models, Spark Models, SPSS models, Tensorflow models etc as Online or Batch deployments. Online deployments predict results in real time while a Batch deployment can be used when the input data is large from a file, data connection or connected data. Both no-code via GUI and code approaches can be used to create deployments. All activities on Watsonx platform are organised and carried out in a collaborative workspaces called Project and deployment spaces. This is where users can come together, collaborate and work with data and other assets to accomplish a particular goal. Collaboration in projects are governed by user roles that give users access rights and permissions on various assets. The access levels define what actions a user can take on what asset.Watsonx governance capabilities accelerate responsible, transparent, and explainable AI workflows that provides end-to-end monitoring for machine learning and generative AI models. Governance flow helps to monitor a customer’s foundation model and machine learning assets collaboratively from request to production. Collect facts about models that are built with IBM tools or third-party providers in a single dashboard to aid in meeting compliance and governance goals.. Watsonx platform with its AutoAI capability helps to automate training of machine learning models with the help of a guided interactive UI. The interface in the process automatically recommends algorithms and pipelines and ranks the best possible pipelines on a leaderboard. This guides the end user to train and select machine learning models with just a few clicks. . Watsonx platform provides with capability to save templates with Prompt Lab for generative AI. With prompt editors that support chat, structured and freeform types users can engineer prompts in a structured or unstructured way and save them as templates for future usage/tweaking. Watsonx platform also supports InstructLab, a novel way for developers to build models specific to their business domains or industries with their own data and train base LLMs with new tasks and skill.  Watsonx platform supports Orchestration Pipelines editor that provides a graphical interface for orchestrating an end-to-end flow of assets from creation through deployment. Assemble and configure a pipeline to create, train, deploy, and update machine learning models and Python scripts.To design a pipeline that you drag nodes onto the canvas, specify objects and parameters, then run and monitor the pipeline.End to end lifecycle of Machine Learning that includes data collection, data transformation, model training, model deployment, model serving, model performance and evaluation and updating over time to avoid bias or drift is comprehensively covered under Orchestration Pipelines.This capability also improves cohesive collaboration between a data scientist and a ModelOps engineer. . Watsonx platform with its governance service can help users to plan for AI governance. The platform provides with tools for end to end monitoring of machine learning and generative ai models and helps to configure, monitor, evaluate and report compliance deviations. This help customers to accelerate and implement responsible, transparent and explainable AI workflows. The platform helps you organise the efforts by building a governance team with each member filling multiple roles, setting up a governance structure on how to manage and act on AI use cases and assets, platform for collaboration to solve common goals and manage assets, to develop plan and workflow to communicate compliance reports in the AI lifecycle. AI factsheets to accumulate information about the models and its performance.Watsonx platform helps to seamlessly integrate machine learning and foundation model deployments to accelerate responsible, transparent and explainable AI workflows with AI governance solutions that provide end to end monitoring of AI models. It brings in AI Factsheets and continuous monitoring of metrics to keep a check on model performance and block drift from desired thresholds on data consistency, AI accuracy and fairness. Watsonx platform supports managing risk and compliance with Governance Console. It’s an integrated governance, risk and compliance (GRC) suite that can be used to identify, manage, monitor and report on risk and compliance initiatives across your enterprise. Governance Console can be used to collect metadata about foundation models and machine learning models to help achieve governance goals and also to develop workflows that support your governance processes.Watsonx platform allows integration with business analytics tools like IBM Cognos dashboards, Cognos Analytics and Planning Analytics and many other analytics and dashboard services. Watsonx platform constantly monitors compute resources and consumption metrics that monitors compute usage used by multiple AI assets like models, notebooks, apps and scripts.Account level monitoring helps users to view consumption details and costs associated whether it be usage of runtime environments or foundation model inferencing based on tokens. The metering capabilities directly influence the monthly billing and provides tools and UI to view summary and billing details. Watsonx platform supports import and deployment of machine learning models that are trained outside of IBM Watson Machine Learning. This can be done easily either via GUI or by using a path to a file or directory or by importing a model object. The platform supports frameworks like PMML, PyTorch, Scikit-learn, Spark. Tensorflow, XGBoost etc.Watsonx platform also supports expansion of SOTA Foundation Models from open source or partners using Bring Your Own Model (BYOM) capability.  Watsonx platform supports scaling of resources manually in deployment space by increasing the number of copies created for your deployment. as well as automatically by using the Red Hat OpenShift Horizontal Pod Autoscaler (HPA) especially for data. The HPA changes the resource allocation of components by increasing or decreasing the number of pods in response to CPU or memory consumption.Will upgrade notebooks infrastructure for significant cost savings via CPU cluster auto-scaling and higher internal discount rate. 12 months roadmap will include enhancements to the existing stack.  Watsonx platform is built on top of a strong data fabric architected data platform that helps you scale enterprise AI and Analytics. The data platform supports open formats to access all your data through a single point of entry and share a single copy of data across your organisation and workloads without needing to migrate or recatalog. This includes fit for purpose query engines, integrated vector database,  embeddable AI powered semantic layer, integration with databases, tools and modern data stacks with the help of connectors and hybrid deployment options to deploy across any cloud or on-premises environments.Watsonx platform supports more than 60 data connectors to access data on various cloud databases. In the next 12 months the platform plans to upgrade and add more data connectors including Databricks and Snowflakes which includes Vector supported databases.  Watsonx platform has lot of inbuilt BI and data visualization tools like Data Refinery and data visualizations.The platform is also integrated with Cognos Analytics an AI-powered automation and insights application. Cognos Analytics brings in new generation of BI with AI capabilities that not only bring an accurate, trusted and complete picture of your business, but forecast what’s coming in the future, predict outcomes and explain why they may happen.This stack will be upgraded to support more Business Intelligence tools with GenAI embeds. 12 months roadmap will also include enhancements to the existing stack.  Watsonx platform allows to organise your assets in a collaborative workspace called Projects. The platform allows customers to link a project to a GitHub repository. To collaborate with stakeholders and other data scientists, users can publish notebooks in GitHub repositories. Users can also use GitHub to back up notebooks for source code management. The platform plans to strengthen the git integration offerings in the next 12 months with more enhancements that will make the integration more strong.  Watsonx platform supports seamless integration with various open source MLOps tools like MLflow, Jenkins, Bamboo, docker registry etc.12 months roadmap will include enhancements to the existing stack.  Watsonx platform is built on top of a strong data fabric architected data platform that helps you scale enterprise AI and Analytics. The data platform supports open formats to access all your data through a single point of entry and share a single copy of data across your organisation and workloads without needing to migrate or recatalog. This includes fit for purpose query engines, integrated vector database,  embeddable AI powered semantic layer, integration with databases, tools and modern data stacks with the help of connectors and hybrid deployment options to deploy across any cloud or on-premises environments.Watsonx platform supports Orchestration pipelines which is built on Elyra canvas to make it easy to run notebooks or scripts as batch jobs, and, therefore, automate common repetitive tasks. Elyra Canvas is an open-source library, which provides React objects that enable applications to quickly create a fully functional flow editor. Users can easily create and edit the flows of linked nodes by using the flow editor.The platform also supports integrating with GUI-driven approach to creating Apache Airflow workflows that implement machine learning pipelines using Jupyter Notebooks and Python scripts.The platform will upgrade the capabilities of pipelines to improve user experience, strengthen FMOps and MLOps coverage and versioning capabilities. 12 months roadmap will also include enhancements and upgrades to the existing stack.  Watsonx platform supports monitoring of AI and ML models deployed for batch inferencing with the help of a seamlessly integrated Governance offering with Open Scale and AI Factsheet. This capability can prepare test data and monitor machine learning and GenAI models to meet governance and compliance goals.12 months roadmap will include enhancements and upgrades to the existing stack.  Watsonx platform supports monitoring of machine learning and AI models that take in text streams as inputs with the help of a seamlessly integrated Governance offering with Open Scale and AI Factsheet. This capability can prepare test data and monitor machine learning and GenAI models to meet governance and compliance goals.12 months roadmap will include enhancements and upgrades to the existing stack.  Watsonx platform includes RStudio, an integrated development environment for working with RScripts. Users can build web applications using R Shiny using R programming language. This enables users to quickly build interactive and data driven web applications without extensive knowledge of web application.Platform plans to upgrade capabilities to easily built web application using frameworks like Streamlit which makes it easier for data scientists and developers to build apps using Python.  Watsonx platform supports integration with Orchestrate tooling that supports rule-based decision modeling for automation.12 months roadmap will include enhancements and upgrades to the existing stack.  Watsonx platform supports a seamless integration with a comprehensive ML/AI governance platform called Watsonx Governance with feature rich monitoring and reporting. It supports managing enterprise risk and compliance with Governance Console which is an integrated governance, risk and compliance (GRC) suite that customers can use to identify, manage, monitor and report on risk and compliance initiatives that span the enterprise. With Governance Console, you can collect metadata about foundation models and machine learning models to help you achieve your governance goals. This suite can also be used to develop workflows that support your governance processes. This platform supports monitoring of LLM specific metrics like accuracy, fairness, quality and drift. The next 12 months will include - improved and enhanced list of metrics to support emerging use cases like RAG. - Tests to address topics like adversarial attacks. - Enhancements to existing list of health metrics around quality and drift. - Metrics and governance for multi lingual language models. - Introduction of social stigma bias detection. - Addition of metrics that brings governance on cost of running LLMs. - Addition of more regulations and coverage across enterprise like out of the box EU AI act and YC Local Law 144, SR 11-7 etc. - More robust and improved coverage across all aspects of AI lifecycle. 